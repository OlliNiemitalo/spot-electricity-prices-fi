{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pörssisähkön hinta ja kulutus\n",
        "Yhdistää Fingrid Datahubista manuaalisesti ladatun kulutuksen Entso-e Transparency Platform SFTP-palvelusta haettuun Nord Pool -pörssisähkön hintahistoriaan.\n",
        "\n",
        "Ennen käyttöä:\n",
        "\n",
        "* Käyttäjän tulee ladata itse tunneittainen kulutusdata osoitteesta https://oma.datahub.fi/.\n",
        "* Käyttäjän tulee rekisteröityä Entso-e Transparency Platform -palveluun osoitteessa https://transparency.entsoe.eu/."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Konfiguraatio\n",
        "\n",
        "Entso-e tiedostojen sijainti määräytyy muuttujan `entso_e_data_local_folder` mukaan. Sijainti voi olla sama kuin kulutustietotiedostoilla muuttujan `consumption_data_local_folder` mukaan ja lopputuotteen hakmistolla muuttujan `output_data_local_folder`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "from pathlib import Path\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import paramiko\n",
        "import os\n",
        "from datetime import datetime, timedelta, timezone\n",
        "\n",
        "entso_e_data_local_folder = f\"{Path.home()}/electricity_data\" # User configurable\n",
        "consumption_data_local_folder = f\"{Path.home()}/electricity_data\" # User configurable\n",
        "output_data_local_folder = f\"{Path.home()}/electricity_data\" # User configurable\n",
        "local_host_keys_filename = f\"{Path.home()}/known_hosts\" # User configurable\n",
        "\n",
        "os.makedirs(entso_e_data_local_folder, exist_ok=True) # Create folder if does not exist\n",
        "\n",
        "def get_entso_e_data_filename(year, month):\n",
        "    return f\"{year}_{month:02}_DayAheadPrices_12.1.D.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Kulutustietojen luku\n",
        "Kaikki `*.csv` -tiedostot ladataan kulutustietokansiosta ja suodatetaan vain toteutuneita tuntikohtaisia kWh-kulutustietoja sisältäviksi. Hyväksyttyjen tiedostojen kulutusdatat yhdistetään."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading consumption data from C:\\Users\\o/electricity_data/*.csv:\n",
            "Read 2195 hours from C:\\Users\\o/electricity_data\\consumption (1).csv\n",
            "Read 1584 hours from C:\\Users\\o/electricity_data\\consumption 2018.csv\n",
            "Read 8760 hours from C:\\Users\\o/electricity_data\\consumption 2019.csv\n",
            "Read 8784 hours from C:\\Users\\o/electricity_data\\consumption 2020.csv\n",
            "Read 8760 hours from C:\\Users\\o/electricity_data\\consumption 2021.csv\n",
            "Read 6691 hours from C:\\Users\\o/electricity_data\\consumption 2022 aiemmin ladattu.csv\n",
            "Read 7223 hours from C:\\Users\\o/electricity_data\\consumption 2022.csv\n",
            "Read 7223 hours from C:\\Users\\o/electricity_data\\consumption.csv\n",
            "\n",
            "Consumption data read for the following (year, month) combinations:\n",
            "[(2018, 10), (2018, 11), (2018, 12), (2019, 1), (2019, 2), (2019, 3), (2019, 4), (2019, 5), (2019, 6), (2019, 7), (2019, 8), (2019, 9), (2019, 10), (2019, 11), (2019, 12), (2020, 1), (2020, 2), (2020, 3), (2020, 4), (2020, 5), (2020, 6), (2020, 7), (2020, 8), (2020, 9), (2020, 10), (2020, 11), (2020, 12), (2021, 1), (2021, 2), (2021, 3), (2021, 4), (2021, 5), (2021, 6), (2021, 7), (2021, 8), (2021, 9), (2021, 10), (2021, 11), (2021, 12), (2022, 1), (2022, 2), (2022, 3), (2022, 4), (2022, 5), (2022, 6), (2022, 7), (2022, 8), (2022, 9), (2022, 10), (2022, 11)]\n"
          ]
        }
      ],
      "source": [
        "consumption_data_datetime_col = \"Alkuaika\"\n",
        "consumption_data_consumption_col = \"Määrä\"\n",
        "consumption_data_resolution_col = \"Resoluutio\"\n",
        "consumption_data_unit_col = \"Yksikkötyyppi\"\n",
        "consumption_data_quality_col = \"Laatu\"\n",
        "\n",
        "def is_consumption_data(filename):\n",
        "    with open(filename, encoding=\"utf-8\") as file:\n",
        "        first_line = file.readline()\n",
        "        return consumption_data_datetime_col in first_line and consumption_data_consumption_col in first_line\n",
        "\n",
        "consumption_dict = {}\n",
        "year_month_dict = {}\n",
        "\n",
        "print(f\"Reading consumption data from {consumption_data_local_folder}/*.csv:\")\n",
        "for filename in filter(is_consumption_data, glob(f\"{consumption_data_local_folder}/*.csv\")):\n",
        "    df = pd.read_csv(filename, encoding=\"utf-8\", sep=\";\", decimal=\",\", index_col=consumption_data_datetime_col)\n",
        "    df = df[(df[consumption_data_quality_col] == \"OK\") & (df[consumption_data_resolution_col] == \"PT1H\") & (df[consumption_data_unit_col] == \"kWh\")]\n",
        "    df.index = pd.to_datetime(df.index, utc=True)\n",
        "    df[consumption_data_consumption_col] = df[consumption_data_consumption_col]\n",
        "    num_hours = 0\n",
        "    for index, row in df.iterrows():\n",
        "        val = row[consumption_data_consumption_col]\n",
        "        if index in consumption_dict:\n",
        "            consumption_dict[index] = max(consumption_dict[index], val) # A larger consumption is probably more up ot date\n",
        "        else:\n",
        "            consumption_dict[index] = val\n",
        "        year_month_dict[(index.year, index.month)] = True\n",
        "        num_hours += 1\n",
        "    print(f\"Read {num_hours} hours from {filename}\")\n",
        "\n",
        "print()\n",
        "print(\"Consumption data read for the following (year, month) combinations:\")\n",
        "print(sorted(year_month_dict.keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Entso-e kirjautumistietojen syöttö"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yeOrFiNRXOF",
        "outputId": "101f709d-b783-475f-889c-80e0ad3876ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entso-e SFTP username and password set\n"
          ]
        }
      ],
      "source": [
        "user = input(\"Entso-e e-mail:\")\n",
        "password = getpass(\"Entso-e password:\")\n",
        "print(\"Entso-e SFTP username and password set\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hintahistorian lataus Entso-e SFTP-serveriltä\n",
        "\n",
        "Hintahistoria ladataan kulutustietoja vastaavien kuukausien ajalta muuttujan `entso_e_data_local_folder` määräämään kansioon. Vain päiväyksiltään paikallisia uudemmat tiedostot ladataan Entso-e SFTP-serveriltä."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "Vm_Lxl4kV9sC",
        "outputId": "8c040c90-8ae4-4f09-ff59-26289a2586e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Opening Entso-e SSH connection\n",
            "Opening Entso-e SFTP connection using the SSH connection\n",
            "Downloading data to C:\\Users\\o/electricity_data:\n",
            "2018_10_DayAheadPrices_12.1.D.csv already up to date\n",
            "2018_11_DayAheadPrices_12.1.D.csv already up to date\n",
            "2018_12_DayAheadPrices_12.1.D.csv already up to date\n",
            "2019_01_DayAheadPrices_12.1.D.csv already up to date\n",
            "2019_02_DayAheadPrices_12.1.D.csv already up to date\n",
            "2019_03_DayAheadPrices_12.1.D.csv already up to date\n",
            "2019_04_DayAheadPrices_12.1.D.csv already up to date\n",
            "2019_05_DayAheadPrices_12.1.D.csv already up to date\n",
            "2019_06_DayAheadPrices_12.1.D.csv already up to date\n",
            "2019_07_DayAheadPrices_12.1.D.csv already up to date\n",
            "2019_08_DayAheadPrices_12.1.D.csv already up to date\n",
            "2019_09_DayAheadPrices_12.1.D.csv already up to date\n",
            "2019_10_DayAheadPrices_12.1.D.csv already up to date\n",
            "2019_11_DayAheadPrices_12.1.D.csv already up to date\n",
            "2019_12_DayAheadPrices_12.1.D.csv already up to date\n",
            "2020_01_DayAheadPrices_12.1.D.csv already up to date\n",
            "2020_02_DayAheadPrices_12.1.D.csv already up to date\n",
            "2020_03_DayAheadPrices_12.1.D.csv already up to date\n",
            "2020_04_DayAheadPrices_12.1.D.csv already up to date\n",
            "2020_05_DayAheadPrices_12.1.D.csv already up to date\n",
            "2020_06_DayAheadPrices_12.1.D.csv already up to date\n",
            "2020_07_DayAheadPrices_12.1.D.csv already up to date\n",
            "2020_08_DayAheadPrices_12.1.D.csv already up to date\n",
            "2020_09_DayAheadPrices_12.1.D.csv already up to date\n",
            "2020_10_DayAheadPrices_12.1.D.csv already up to date\n",
            "2020_11_DayAheadPrices_12.1.D.csv already up to date\n",
            "2020_12_DayAheadPrices_12.1.D.csv already up to date\n",
            "2021_01_DayAheadPrices_12.1.D.csv already up to date\n",
            "2021_02_DayAheadPrices_12.1.D.csv already up to date\n",
            "2021_03_DayAheadPrices_12.1.D.csv already up to date\n",
            "2021_04_DayAheadPrices_12.1.D.csv already up to date\n",
            "2021_05_DayAheadPrices_12.1.D.csv already up to date\n",
            "2021_06_DayAheadPrices_12.1.D.csv already up to date\n",
            "2021_07_DayAheadPrices_12.1.D.csv already up to date\n",
            "2021_08_DayAheadPrices_12.1.D.csv already up to date\n",
            "2021_09_DayAheadPrices_12.1.D.csv already up to date\n",
            "2021_10_DayAheadPrices_12.1.D.csv already up to date\n",
            "2021_11_DayAheadPrices_12.1.D.csv already up to date\n",
            "2021_12_DayAheadPrices_12.1.D.csv already up to date\n",
            "2022_01_DayAheadPrices_12.1.D.csv already up to date\n",
            "2022_02_DayAheadPrices_12.1.D.csv already up to date\n",
            "2022_03_DayAheadPrices_12.1.D.csv already up to date\n",
            "2022_04_DayAheadPrices_12.1.D.csv already up to date\n",
            "2022_05_DayAheadPrices_12.1.D.csv already up to date\n",
            "2022_06_DayAheadPrices_12.1.D.csv already up to date\n",
            "2022_07_DayAheadPrices_12.1.D.csv already up to date\n",
            "2022_08_DayAheadPrices_12.1.D.csv already up to date\n",
            "2022_09_DayAheadPrices_12.1.D.csv already up to date\n",
            "2022_10_DayAheadPrices_12.1.D.csv already up to date\n",
            "2022_11_DayAheadPrices_12.1.D.csv already up to date\n",
            "Finished downloading data\n",
            "Closed SFTP connection\n",
            "Closed SSH connection\n"
          ]
        }
      ],
      "source": [
        "entso_e_host = \"sftp-transparency.entsoe.eu\"\n",
        "entso_e_port = 22\n",
        "entso_e_data_remote_folder = \"/TP_export/DayAheadPrices_12.1.D\"\n",
        "\n",
        "class PromptPolicy(paramiko.client.MissingHostKeyPolicy):\n",
        "    def missing_host_key(self, client, hostname, key):\n",
        "        answer = input(f\"Accept new key {key.get_base64()} (y/n)?\")\n",
        "        if answer == \"y\":\n",
        "            answer = input(f\"Save key in {local_host_keys_filename} (y/n)?\")\n",
        "            if answer == \"y\":\n",
        "                client._host_keys.add(hostname, key.get_name(), key)\n",
        "                Path(client._host_keys_filename).touch()\n",
        "                client.save_host_keys(client._host_keys_filename)\n",
        "                print(f\"Saved key in {client._host_keys_filename}\")\n",
        "            return\n",
        "        raise Exception(\"Unknown host key, not accepted by user\")\n",
        "\n",
        "ssh = paramiko.client.SSHClient()\n",
        "ssh.load_system_host_keys()\n",
        "try:\n",
        "    ssh.load_host_keys(local_host_keys_filename)\n",
        "except:\n",
        "    None\n",
        "promptPolicy = PromptPolicy()\n",
        "ssh.set_missing_host_key_policy(promptPolicy)\n",
        "try:\n",
        "    print(\"Opening Entso-e SSH connection\")\n",
        "    ssh.connect(entso_e_host, port=entso_e_port, username=user, password=password)\n",
        "    try:\n",
        "        print(\"Opening Entso-e SFTP connection using the SSH connection\")\n",
        "        sftp = ssh.open_sftp()\n",
        "        try:\n",
        "            print(f\"Downloading data to {entso_e_data_local_folder}:\")\n",
        "            for year, month in sorted(year_month_dict.keys()):                \n",
        "                entso_e_data_filename = get_entso_e_data_filename(year, month)\n",
        "                try:\n",
        "                    st_mtime = sftp.stat(f\"{entso_e_data_remote_folder}/{entso_e_data_filename}\").st_mtime\n",
        "                    try:\n",
        "                        local_st_mtime = os.stat(f\"{entso_e_data_local_folder}/{entso_e_data_filename}\").st_mtime\n",
        "                    except:\n",
        "                        local_st_mtime = 0\n",
        "                    if st_mtime == local_st_mtime:\n",
        "                        print(f\"{entso_e_data_filename} already up to date\")\n",
        "                    else:\n",
        "                        print(f\"{entso_e_data_filename} downloading...\")\n",
        "                        sftp.get(f\"{entso_e_data_remote_folder}/{entso_e_data_filename}\", f\"{entso_e_data_local_folder}/{entso_e_data_filename}\")\n",
        "                        try:\n",
        "                            os.utime(f\"{entso_e_data_local_folder}/{entso_e_data_filename}\", (st_mtime, st_mtime))\n",
        "                        except:\n",
        "                            print(\"ERROR: Could not update modified time\")\n",
        "                except:\n",
        "                    print(f\"{entso_e_data_filename} not available from Entso-e\")\n",
        "            print(f\"Finished downloading data\")\n",
        "        except:\n",
        "            print(\"ERROR downloading data\")        \n",
        "        sftp.close()\n",
        "        print(\"Closed SFTP connection\")\n",
        "    except:\n",
        "        print(\"ERROR opening SFTP connection\")\n",
        "    ssh.close()\n",
        "    print(\"Closed SSH connection\")\n",
        "except:\n",
        "    print(\"ERROR opening SSH connection\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hintatietojen lataaminen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading price data...\n",
            "Finished reading price data\n"
          ]
        }
      ],
      "source": [
        "entso_e_data_datetime_col = \"DateTime\"\n",
        "entso_e_data_area_col = \"AreaCode\"\n",
        "entso_e_data_resolution_col = \"ResolutionCode\"\n",
        "entso_e_data_currency_col = \"Currency\"\n",
        "entso_e_data_price_col = \"Price\"\n",
        "\n",
        "price_dict = {}\n",
        "\n",
        "print(f\"Reading price data...\")\n",
        "for year, month in sorted(year_month_dict.keys()):\n",
        "    try:\n",
        "        filename = get_entso_e_data_filename(year, month)\n",
        "        df = pd.read_csv(f\"{entso_e_data_local_folder}/{filename}\", encoding=\"utf-8\", sep=\"\\t\", decimal=\".\", index_col=entso_e_data_datetime_col)\n",
        "        df = df[(df[entso_e_data_area_col] == \"10YFI-1--------U\") & (df[entso_e_data_resolution_col] == \"PT60M\") & (df[entso_e_data_currency_col] == \"EUR\")]\n",
        "        df.index = pd.to_datetime(df.index, utc=True)\n",
        "        df[entso_e_data_price_col] = df[entso_e_data_price_col]\n",
        "        for index, row in df.iterrows():\n",
        "            price_dict[index] = row[entso_e_data_price_col]\n",
        "    except:\n",
        "        print(f\"ERROR reading/parsing {entso_e_data_local_folder}/{filename}\")\n",
        "        \n",
        "print(\"Finished reading price data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hinta- ja kulutustietojen yhdistäminen\n",
        "\n",
        "Anna tarkasteltavan aikavälin ensimmäinen tunti muuttujassa `start_datetime_string` ja viimeistä tuntia seuraava tunti muuttujassa `end_datetime_string` ISO-formaatissa. Ajat voivat määritellä myös aikavyöhykkeen, esim. `2011-11-04T00:00:00+02:00`. Jos aikavyöhykettä ei määritetä, käytetään tietokoneen aikavyöhykettä.\n",
        "\n",
        "Yhdistetyt kulutus- ja hintatiedot tallentuvat aiemmin määritetyn muuttujan `output_data_local_folder` mukaiseen hakemistoon nimellä `Consumption and spot price ALKUAIKA to LOPPUAIKA.csv` johon sijoitetaan edellämainitut ajat. CSV-tiedostoon kirjoitetut ajat ovat ISO-formaatissa UTC-aikavyöhykkeessä."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote output file C:\\Users\\o/electricity_data/Consumption and spot price 2022-11-01 to 2022-12-01.csv\n"
          ]
        }
      ],
      "source": [
        "start_datetime_string = \"2022-11-01\" # User configurable. Must be the start of an hour\n",
        "end_datetime_string = \"2022-12-01\" # User configurable. Note that this datetime is excluded but the previous hour will be included\n",
        "\n",
        "start_datetime = datetime.fromisoformat(start_datetime_string).astimezone(timezone.utc)\n",
        "end_datetime = datetime.fromisoformat(end_datetime_string).astimezone(timezone.utc)\n",
        "hour_timedelta = timedelta(hours=1)\n",
        "t = start_datetime\n",
        "datetimes = []\n",
        "consumptions = []\n",
        "prices = []\n",
        "while t < end_datetime:\n",
        "    datetimes.append(t)\n",
        "    try:\n",
        "        consumptions.append(consumption_dict[t])\n",
        "    except:\n",
        "        consumptions.append(\"\")\n",
        "    try:\n",
        "        prices.append(price_dict[t])\n",
        "    except:\n",
        "        prices.append(\"\")\n",
        "    t += hour_timedelta\n",
        "output = pd.DataFrame({\"DateTime\": datetimes, \"Consumption (kWh)\": consumptions, \"Price (€/MWh)\": prices})\n",
        "output.set_index(\"DateTime\")\n",
        "output_filename = f\"{output_data_local_folder}/Consumption and spot price {start_datetime_string.replace('+','p')} to {end_datetime_string.replace('+','p')}.csv\"\n",
        "output.to_csv(output_filename, index=False)\n",
        "print(f\"Wrote output file {output_filename}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('.venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "d904e19baa4e0b7562dd659bde2d7ba4d4878d31e119864319cac6bba9d9af6b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
